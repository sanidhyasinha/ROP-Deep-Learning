# -*- coding: utf-8 -*-
"""ROP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sZWSXD9HS1T-tWQ6YyfJXzoV1GONrwS6
"""

# ROP Classification Model with Direct File Upload in Google Colab

# First, run this cell to set up file upload
from google.colab import files
import os
import shutil

# Create base directory for uploads
base_dir = '/content/ROP'
os.makedirs(base_dir, exist_ok=True)
os.makedirs(os.path.join(base_dir, 'ROP'), exist_ok=True)
os.makedirs(os.path.join(base_dir, 'NON_ROP'), exist_ok=True)

print("Please upload ROP images:")
rop_files = files.upload()

print("\nPlease upload NON_ROP images:")
non_rop_files = files.upload()

# Move uploaded ROP files
for filename in rop_files.keys():
    shutil.move(filename, os.path.join(base_dir, 'ROP', filename))

# Move uploaded NON_ROP files
for filename in non_rop_files.keys():
    shutil.move(filename, os.path.join(base_dir, 'NON_ROP', filename))

# Now run the rest of the script
import cv2
import random
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.utils import img_to_array, load_img
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# Set random seeds for reproducibility
np.random.seed(1)
tf.random.set_seed(1)

# Ensure the augmented data directory exists
augmented_path = os.path.join(base_dir, 'RETINAaugmented')
os.makedirs(augmented_path, exist_ok=True)
os.makedirs(os.path.join(augmented_path, 'ROP'), exist_ok=True)
os.makedirs(os.path.join(augmented_path, 'NON_ROP'), exist_ok=True)

# Image parameters
categories = ['ROP', 'NON_ROP']
img_size = 224

# Loading and preprocessing non-augmented data
def load_data(base_path, categories, img_size):
    data = []
    for category in categories:
        path = os.path.join(base_path, category)
        class_num = categories.index(category)
        for img in os.listdir(path):
            try:
                img_path = os.path.join(path, img)
                img_array = cv2.imread(img_path)
                new_array = cv2.resize(img_array, (img_size, img_size))
                data.append([new_array, class_num])
            except Exception as e:
                print(f"Error processing {img_path}: {e}")
    return data

# Load initial data
data_nonaug = load_data(base_dir, categories, img_size)
print('\nNumber of images before augmentation: {0}'.format(len(data_nonaug)))

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=[0.8, 1.2],
    horizontal_flip=True,
    vertical_flip=True,
    fill_mode='nearest'
)

# Augment images
def augment_images(base_path, augmented_path, category, datagen, max_augmentations=50):
    path = os.path.join(base_path, category)
    augmented_category_path = os.path.join(augmented_path, category)

    for img in os.listdir(path):
        try:
            image = load_img(os.path.join(path, img))
            x = img_to_array(image)
            x = x.reshape((1,) + x.shape)

            i = 0
            for batch in datagen.flow(x, batch_size=1,
                                      save_to_dir=augmented_category_path,
                                      save_prefix=category, save_format='jpg'):
                i += 1
                if i > max_augmentations:
                    break
        except Exception as e:
            print(f"Error augmenting {img}: {e}")

# Perform augmentation
augment_images(base_dir, augmented_path, 'ROP', datagen)
augment_images(base_dir, augmented_path, 'NON_ROP', datagen)

# Load augmented data
data = load_data(augmented_path, categories, img_size)
print('\nNumber of images for training: {0}'.format(len(data)))

# Shuffle and prepare data
random.shuffle(data)

X = []
y = []
for features, label in data:
    X.append(features)
    y.append(label)

X = np.array(X).reshape(-1, img_size, img_size, 3)
y = np.array(y)

# Normalization
X = X / 255.0

# Split data
train_ratio = 0.80
val_ratio = 0.10
test_ratio = 0.10

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1 - train_ratio), random_state=1)
X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + val_ratio), random_state=1)

# Model callbacks
monitor_val_acc = EarlyStopping(monitor='val_accuracy', patience=5)
model_checkpoint = ModelCheckpoint('/content/best_ROP_model.hdf5', save_best_only=True)

# Optimizer
opt = Adam(learning_rate=1e-4)

# VGG19-inspired Architecture
model = Sequential([
    # Block 1
    Conv2D(64, (3,3), activation='relu', input_shape=X.shape[1:], padding='same'),
    Conv2D(64, (3,3), activation='relu', padding='same'),
    MaxPooling2D(pool_size=(2,2), strides=2, padding='same'),

    # Block 2
    Conv2D(128, (3,3), activation='relu', padding='same'),
    Conv2D(128, (3,3), activation='relu', padding='same'),
    MaxPooling2D(pool_size=(2,2), strides=2, padding='same'),

    # Block 3
    Conv2D(256, (3,3), activation='relu', padding='same'),
    Conv2D(256, (3,3), activation='relu', padding='same'),
    Conv2D(256, (3,3), activation='relu', padding='same'),
    MaxPooling2D(pool_size=(2,2), strides=2),

    # Block 4
    Conv2D(512, (3,3), activation='relu', padding='same'),
    Conv2D(512, (3,3), activation='relu', padding='same'),
    MaxPooling2D(pool_size=(2,2), strides=2, padding='same'),

    # Fully Connected Layer
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(2, activation='softmax')
])

# Compile model
model.compile(optimizer=opt,
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train model
history = model.fit(X_train, y_train,
                    epochs=30,
                    batch_size=32,
                    validation_data=(X_val, y_val),
                    callbacks=[monitor_val_acc, model_checkpoint])

# Visualize training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.tight_layout()
plt.savefig('/content/training_history.png')
plt.close()

# Model evaluation
y_model = model.predict(X_test)
y_pred = np.argmax(y_model, axis=1)

print('\nClassification Report:')
print(classification_report(y_test, y_pred))

print('\nConfusion Matrix:')
cm = confusion_matrix(y_test, y_pred)
print(cm)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g',
            xticklabels=['ROP', 'NonROP'],
            yticklabels=['ROP', 'NonROP'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.tight_layout()
plt.savefig('/content/confusion_matrix.png')
plt.close()

# Optional: Download model and visualizations
from google.colab import files

# Download the best model
files.download('/content/best_ROP_model.hdf5')
files.download('/content/training_history.png')
files.download('/content/confusion_matrix.png')

print("\nTraining completed. Model and visualizations have been saved and downloaded.")